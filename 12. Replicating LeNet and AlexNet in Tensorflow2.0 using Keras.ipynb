{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"12. Replicating LeNet and AlexNet in Tensorflow2.0 using Keras.ipynb","provenance":[],"authorship_tag":"ABX9TyNVBznFIBy6KHgV2JVX29VL"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SWXXpSmUrd24"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Replicating LeNet and AlexNet in Tensorflow2.0 using Keras**\n","\n","---\n","\n","In this lesson, we use **Keras with a TensorFlow 2.0** Backend to to replicate both **LeNet and AlexNet** in Keras and train it to **recognize handwritten digits in the MNIST dataset and the 10 images classes of CIFAR10**\n","1. Replicate the LeNet CNN Architecture \n","2. Replicate the AlexNet CNN Architecture "]},{"cell_type":"markdown","metadata":{"id":"DlFbhDyYrgTp"},"source":["## **Let's construct LeNet in Keras!**\n","\n","![](https://www.researchgate.net/profile/Sheraz_Khan8/publication/321586653/figure/fig4/AS:568546847014912@1512563539828/The-LeNet-5-Architecture-a-convolutional-neural-network.png)\n","## **LeNet Architecture**\n","S.No | Layers | Output Shape (Height, Width, Channels)\n","--- | --- | ---\n","1 | Input Layer | 32 x 32 x 1\n","2 | Conv2d [6 Filters of size = 5x5, stride = 1, padding = 0 ] | 28 x 28 x 6\n","3 | Average Pooling [stride = 2, padding = 0] | 14 x 14 x 6\n","4 | Conv2d [16 Filters of size = 5x5, stride = 1, padding = 0 ] | 10 x 10 x 16\n","5 | Average Pooling [stride = 2, padding = 0] | 5 x 5 x 16\n","6 | Conv2d [120 Filters of size = 5x5, stride = 1, padding = 0 ] | 1 x 1 x 120\n","7 | Linear1 Layer | 120 \n","8 | Linear2 Layer | 84 \n","9 | Final Linear Layer | 10\n","\n","\n","### **Loading and preprocessing our Data**"]},{"cell_type":"code","metadata":{"id":"4Cr4L1LjRqVk","executionInfo":{"status":"ok","timestamp":1638645995602,"user_tz":0,"elapsed":361,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adadelta\n","\n","# loads the MNIST dataset\n","(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n","\n","# Lets store the number of rows and columns\n","img_rows = x_train[0].shape[0]\n","img_cols = x_train[1].shape[0]\n","\n","# Getting our date in the right 'shape' needed for Keras\n","# We need to add a 4th dimenion to our date thereby changing our\n","# Our original image shape of (60000,28,28) to (60000,28,28,1)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","\n","# store the shape of a single image \n","input_shape = (img_rows, img_cols, 1)\n","\n","# change our image type to float32 data type\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n","x_train /= 255\n","x_test /= 255\n","\n","# Now we one hot encode outputs\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","num_classes = y_test.shape[1]\n","num_pixels = x_train.shape[1] * x_train.shape[2]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywUXRWhKtMCZ"},"source":["### **Now let's create our layers to replicate LeNet**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QeVx6xALslPK","executionInfo":{"status":"ok","timestamp":1638646092114,"user_tz":0,"elapsed":615,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"}},"outputId":"fc6c4830-bf01-4061-c320-d4dffb5dffc4"},"source":["# create model\n","model = Sequential()\n","\n","# 2 sets of CRP (Convolution, RELU, Pooling)\n","model.add(Conv2D(6, (5, 5),\n","                 padding = \"same\", # to set padding at 0, use \"valid\"\n","                 input_shape = input_shape))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","\n","model.add(Conv2D(16, (5, 5),\n","                 padding = \"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","\n","model.add(Conv2D(120, (5, 5),\n","                 padding = \"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","\n","# Fully connected layers (w/ RELU)\n","model.add(Flatten())\n","model.add(Dense(120))\n","model.add(Activation(\"relu\"))\n","\n","model.add(Dense(84))\n","model.add(Activation(\"relu\"))\n","# Softmax (for classification)\n","model.add(Dense(num_classes))\n","model.add(Activation(\"softmax\"))\n","           \n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = Adadelta(),\n","              metrics = ['accuracy'])\n","    \n","print(model.summary())"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 28, 28, 6)         156       \n","                                                                 \n"," activation_8 (Activation)   (None, 28, 28, 6)         0         \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 14, 14, 6)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 14, 14, 16)        2416      \n","                                                                 \n"," activation_9 (Activation)   (None, 14, 14, 16)        0         \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 7, 7, 16)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 7, 7, 120)         48120     \n","                                                                 \n"," activation_10 (Activation)  (None, 7, 7, 120)         0         \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 3, 3, 120)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1080)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 120)               129720    \n","                                                                 \n"," activation_11 (Activation)  (None, 120)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 84)                10164     \n","                                                                 \n"," activation_12 (Activation)  (None, 84)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 10)                850       \n","                                                                 \n"," activation_13 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 191,426\n","Trainable params: 191,426\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"6XEqUat3tQph"},"source":["### **Now let us train LeNet on our MNIST Dataset**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2f2gBg44tOwq","executionInfo":{"status":"ok","timestamp":1638646368375,"user_tz":0,"elapsed":203686,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"}},"outputId":"70e852eb-6a79-4cd9-9f85-16f4006deb4c"},"source":["# Training Parameters\n","batch_size = 128\n","epochs = 50\n","\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test),\n","          shuffle=True)\n","\n","model.save(\"mnist_LeNet.h5\")\n","\n","# Evaluate the performance of our trained model\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 2.0439 - accuracy: 0.5682 - val_loss: 1.9940 - val_accuracy: 0.6006\n","Epoch 2/50\n","469/469 [==============================] - 3s 7ms/step - loss: 1.9453 - accuracy: 0.6129 - val_loss: 1.8772 - val_accuracy: 0.6403\n","Epoch 3/50\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8140 - accuracy: 0.6494 - val_loss: 1.7264 - val_accuracy: 0.6848\n","Epoch 4/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.6525 - accuracy: 0.6900 - val_loss: 1.5497 - val_accuracy: 0.7177\n","Epoch 5/50\n","469/469 [==============================] - 3s 7ms/step - loss: 1.4722 - accuracy: 0.7251 - val_loss: 1.3636 - val_accuracy: 0.7484\n","Epoch 6/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.2930 - accuracy: 0.7526 - val_loss: 1.1892 - val_accuracy: 0.7791\n","Epoch 7/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.1321 - accuracy: 0.7765 - val_loss: 1.0402 - val_accuracy: 0.7980\n","Epoch 8/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.9985 - accuracy: 0.7920 - val_loss: 0.9203 - val_accuracy: 0.8100\n","Epoch 9/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8918 - accuracy: 0.8049 - val_loss: 0.8261 - val_accuracy: 0.8218\n","Epoch 10/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8075 - accuracy: 0.8162 - val_loss: 0.7516 - val_accuracy: 0.8311\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7403 - accuracy: 0.8263 - val_loss: 0.6920 - val_accuracy: 0.8386\n","Epoch 12/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.6857 - accuracy: 0.8349 - val_loss: 0.6434 - val_accuracy: 0.8472\n","Epoch 13/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6411 - accuracy: 0.8446 - val_loss: 0.6036 - val_accuracy: 0.8535\n","Epoch 14/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6038 - accuracy: 0.8508 - val_loss: 0.5694 - val_accuracy: 0.8605\n","Epoch 15/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.5719 - accuracy: 0.8572 - val_loss: 0.5399 - val_accuracy: 0.8668\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5441 - accuracy: 0.8635 - val_loss: 0.5147 - val_accuracy: 0.8707\n","Epoch 17/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5199 - accuracy: 0.8684 - val_loss: 0.4915 - val_accuracy: 0.8749\n","Epoch 18/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4984 - accuracy: 0.8733 - val_loss: 0.4717 - val_accuracy: 0.8810\n","Epoch 19/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4793 - accuracy: 0.8773 - val_loss: 0.4532 - val_accuracy: 0.8846\n","Epoch 20/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4619 - accuracy: 0.8813 - val_loss: 0.4373 - val_accuracy: 0.8874\n","Epoch 21/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4463 - accuracy: 0.8845 - val_loss: 0.4225 - val_accuracy: 0.8919\n","Epoch 22/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4321 - accuracy: 0.8880 - val_loss: 0.4091 - val_accuracy: 0.8937\n","Epoch 23/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4191 - accuracy: 0.8907 - val_loss: 0.3965 - val_accuracy: 0.8964\n","Epoch 24/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4070 - accuracy: 0.8932 - val_loss: 0.3851 - val_accuracy: 0.8990\n","Epoch 25/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3958 - accuracy: 0.8956 - val_loss: 0.3744 - val_accuracy: 0.9015\n","Epoch 26/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8976 - val_loss: 0.3650 - val_accuracy: 0.9035\n","Epoch 27/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3764 - accuracy: 0.8997 - val_loss: 0.3559 - val_accuracy: 0.9047\n","Epoch 28/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3676 - accuracy: 0.9016 - val_loss: 0.3476 - val_accuracy: 0.9059\n","Epoch 29/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3594 - accuracy: 0.9035 - val_loss: 0.3398 - val_accuracy: 0.9085\n","Epoch 30/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3518 - accuracy: 0.9052 - val_loss: 0.3323 - val_accuracy: 0.9101\n","Epoch 31/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3446 - accuracy: 0.9069 - val_loss: 0.3254 - val_accuracy: 0.9117\n","Epoch 32/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3377 - accuracy: 0.9084 - val_loss: 0.3194 - val_accuracy: 0.9136\n","Epoch 33/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3313 - accuracy: 0.9103 - val_loss: 0.3130 - val_accuracy: 0.9145\n","Epoch 34/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3252 - accuracy: 0.9115 - val_loss: 0.3074 - val_accuracy: 0.9155\n","Epoch 35/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3195 - accuracy: 0.9131 - val_loss: 0.3019 - val_accuracy: 0.9170\n","Epoch 36/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3140 - accuracy: 0.9143 - val_loss: 0.2964 - val_accuracy: 0.9179\n","Epoch 37/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3089 - accuracy: 0.9153 - val_loss: 0.2915 - val_accuracy: 0.9193\n","Epoch 38/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3038 - accuracy: 0.9166 - val_loss: 0.2867 - val_accuracy: 0.9205\n","Epoch 39/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2992 - accuracy: 0.9172 - val_loss: 0.2823 - val_accuracy: 0.9216\n","Epoch 40/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2947 - accuracy: 0.9183 - val_loss: 0.2784 - val_accuracy: 0.9232\n","Epoch 41/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2904 - accuracy: 0.9194 - val_loss: 0.2740 - val_accuracy: 0.9241\n","Epoch 42/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2862 - accuracy: 0.9203 - val_loss: 0.2701 - val_accuracy: 0.9251\n","Epoch 43/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2823 - accuracy: 0.9212 - val_loss: 0.2662 - val_accuracy: 0.9264\n","Epoch 44/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2786 - accuracy: 0.9219 - val_loss: 0.2628 - val_accuracy: 0.9269\n","Epoch 45/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2749 - accuracy: 0.9227 - val_loss: 0.2592 - val_accuracy: 0.9282\n","Epoch 46/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2713 - accuracy: 0.9237 - val_loss: 0.2558 - val_accuracy: 0.9287\n","Epoch 47/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2679 - accuracy: 0.9247 - val_loss: 0.2526 - val_accuracy: 0.9293\n","Epoch 48/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2646 - accuracy: 0.9253 - val_loss: 0.2496 - val_accuracy: 0.9300\n","Epoch 49/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2615 - accuracy: 0.9258 - val_loss: 0.2465 - val_accuracy: 0.9309\n","Epoch 50/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2584 - accuracy: 0.9268 - val_loss: 0.2437 - val_accuracy: 0.9313\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2437 - accuracy: 0.9313\n","Test loss: 0.24367770552635193\n","Test accuracy: 0.9312999844551086\n"]}]},{"cell_type":"markdown","metadata":{"id":"b4i3pvXxtf32"},"source":["## **Now let's replicate AlexNET and train in on the CIFAR10 Dataset**\n","\n","AlexNet was the 2012 ImageNet winner achieved a top-5 error of 15.3%, more than 10.8 percentage points lower than that of the runner up!\n","\n","![](https://paperswithcode.com/media/methods/Screen_Shot_2020-06-22_at_6.35.45_PM.png)\n","\n","![](https://production-media.paperswithcode.com/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_UI-juKTRLa","executionInfo":{"status":"ok","timestamp":1638646493916,"user_tz":0,"elapsed":83886,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"}},"outputId":"bcaaffb2-8890-4af0-cffc-c10269754fcd"},"source":["from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adadelta\n","from tensorflow.keras.utils import to_categorical\n","\n","# Loads the CIFAR dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Display our data shape/dimensions\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Now we one hot encode outputs\n","num_classes = 10\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 81s 0us/step\n","170508288/170498071 [==============================] - 81s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJQPK5fKvxrn","executionInfo":{"status":"ok","timestamp":1638646639662,"user_tz":0,"elapsed":665,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"}},"outputId":"6df079c0-16c7-4d29-a153-3ad0760b6ba9"},"source":["l2_reg = 0.001\n","\n","# Initialize model\n","model = Sequential()\n","\n","# 1st Conv Layer \n","model.add(Conv2D(96, (11, 11), input_shape=x_train.shape[1:],\n","    padding='same', kernel_regularizer=l2(l2_reg)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 2nd Conv Layer \n","model.add(Conv2D(256, (5, 5), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 3rd Conv Layer \n","model.add(ZeroPadding2D((1, 1)))\n","model.add(Conv2D(512, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 4th Conv Layer \n","model.add(ZeroPadding2D((1, 1)))\n","model.add(Conv2D(1024, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","# 5th Conv Layer \n","model.add(ZeroPadding2D((1, 1)))\n","model.add(Conv2D(1024, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 1st FC Layer\n","model.add(Flatten())\n","model.add(Dense(3072))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","# 2nd FC Layer\n","model.add(Dense(4096))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","# 3rd FC Layer\n","model.add(Dense(num_classes))\n","model.add(BatchNormalization())\n","model.add(Activation('softmax'))\n","\n","print(model.summary())\n","\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = Adadelta(),\n","              metrics = ['accuracy'])\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_9 (Conv2D)           (None, 32, 32, 96)        34944     \n","                                                                 \n"," batch_normalization (BatchN  (None, 32, 32, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," activation_14 (Activation)  (None, 32, 32, 96)        0         \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 16, 16, 96)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 16, 16, 256)       614656    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_15 (Activation)  (None, 16, 16, 256)       0         \n","                                                                 \n"," max_pooling2d_9 (MaxPooling  (None, 8, 8, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," zero_padding2d (ZeroPadding  (None, 10, 10, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 10, 10, 512)       1180160   \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 10, 10, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_16 (Activation)  (None, 10, 10, 512)       0         \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 5, 5, 512)        0         \n"," g2D)                                                            \n","                                                                 \n"," zero_padding2d_1 (ZeroPaddi  (None, 7, 7, 512)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 7, 7, 1024)        4719616   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 7, 7, 1024)       4096      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_17 (Activation)  (None, 7, 7, 1024)        0         \n","                                                                 \n"," zero_padding2d_2 (ZeroPaddi  (None, 9, 9, 1024)       0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 9, 9, 1024)        9438208   \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 9, 9, 1024)       4096      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_18 (Activation)  (None, 9, 9, 1024)        0         \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 4, 4, 1024)       0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_2 (Flatten)         (None, 16384)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 3072)              50334720  \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 3072)             12288     \n"," hNormalization)                                                 \n","                                                                 \n"," activation_19 (Activation)  (None, 3072)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 3072)              0         \n","                                                                 \n"," dense_7 (Dense)             (None, 4096)              12587008  \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," activation_20 (Activation)  (None, 4096)              0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_8 (Dense)             (None, 10)                40970     \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 10)               40        \n"," hNormalization)                                                 \n","                                                                 \n"," activation_21 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 78,990,642\n","Trainable params: 78,970,462\n","Non-trainable params: 20,180\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"qDyixr27vzXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638647975083,"user_tz":0,"elapsed":1297281,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"}},"outputId":"ccfec7ab-9ebc-4d1f-d8e8-38ebdd1f3b00"},"source":["# Training Parameters\n","batch_size = 64\n","epochs = 25\n","\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test),\n","          shuffle=True)\n","\n","model.save(\"CIFAR10_AlexNet_10_Epoch.h5\")\n","\n","# Evaluate the performance of our trained model\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","782/782 [==============================] - 54s 66ms/step - loss: 2.1324 - accuracy: 0.2493 - val_loss: 1.7545 - val_accuracy: 0.3977\n","Epoch 2/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.8408 - accuracy: 0.3426 - val_loss: 1.6595 - val_accuracy: 0.4375\n","Epoch 3/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.7434 - accuracy: 0.3880 - val_loss: 1.5984 - val_accuracy: 0.4629\n","Epoch 4/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.6737 - accuracy: 0.4179 - val_loss: 1.5540 - val_accuracy: 0.4834\n","Epoch 5/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.6273 - accuracy: 0.4393 - val_loss: 1.5163 - val_accuracy: 0.4961\n","Epoch 6/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.5869 - accuracy: 0.4583 - val_loss: 1.4908 - val_accuracy: 0.5086\n","Epoch 7/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.5578 - accuracy: 0.4705 - val_loss: 1.4660 - val_accuracy: 0.5212\n","Epoch 8/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.5282 - accuracy: 0.4869 - val_loss: 1.4448 - val_accuracy: 0.5288\n","Epoch 9/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.5007 - accuracy: 0.4985 - val_loss: 1.4274 - val_accuracy: 0.5387\n","Epoch 10/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.4800 - accuracy: 0.5092 - val_loss: 1.4109 - val_accuracy: 0.5439\n","Epoch 11/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.4589 - accuracy: 0.5175 - val_loss: 1.3988 - val_accuracy: 0.5498\n","Epoch 12/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.4399 - accuracy: 0.5274 - val_loss: 1.3820 - val_accuracy: 0.5578\n","Epoch 13/25\n","782/782 [==============================] - 52s 66ms/step - loss: 1.4189 - accuracy: 0.5393 - val_loss: 1.3718 - val_accuracy: 0.5616\n","Epoch 14/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.4015 - accuracy: 0.5475 - val_loss: 1.3571 - val_accuracy: 0.5674\n","Epoch 15/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.3872 - accuracy: 0.5544 - val_loss: 1.3450 - val_accuracy: 0.5744\n","Epoch 16/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.3694 - accuracy: 0.5620 - val_loss: 1.3389 - val_accuracy: 0.5812\n","Epoch 17/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.3533 - accuracy: 0.5735 - val_loss: 1.3306 - val_accuracy: 0.5818\n","Epoch 18/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.3397 - accuracy: 0.5781 - val_loss: 1.3155 - val_accuracy: 0.5874\n","Epoch 19/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.3260 - accuracy: 0.5851 - val_loss: 1.3089 - val_accuracy: 0.5901\n","Epoch 20/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.3074 - accuracy: 0.5936 - val_loss: 1.3025 - val_accuracy: 0.5968\n","Epoch 21/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.2987 - accuracy: 0.6000 - val_loss: 1.2940 - val_accuracy: 0.5978\n","Epoch 22/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.2843 - accuracy: 0.6065 - val_loss: 1.2864 - val_accuracy: 0.6035\n","Epoch 23/25\n","782/782 [==============================] - 52s 66ms/step - loss: 1.2692 - accuracy: 0.6167 - val_loss: 1.2841 - val_accuracy: 0.6053\n","Epoch 24/25\n","782/782 [==============================] - 52s 66ms/step - loss: 1.2555 - accuracy: 0.6204 - val_loss: 1.2711 - val_accuracy: 0.6091\n","Epoch 25/25\n","782/782 [==============================] - 51s 66ms/step - loss: 1.2447 - accuracy: 0.6268 - val_loss: 1.2687 - val_accuracy: 0.6101\n","313/313 [==============================] - 5s 14ms/step - loss: 1.2687 - accuracy: 0.6101\n","Test loss: 1.2686904668807983\n","Test accuracy: 0.6100999712944031\n"]}]},{"cell_type":"markdown","metadata":{"id":"CxAFWgUDBcO9"},"source":["## **Current Top Performers in CIFAR10**\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/Screenshot%202021-12-04%20at%207.56.25%20pm.png)"]},{"cell_type":"code","metadata":{"id":"rRzWjpSCw4Mf"},"source":[""],"execution_count":null,"outputs":[]}]}